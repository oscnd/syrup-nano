{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c6d48578be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02081c92d0fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"nampdn-ai/tiny-webtext\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12911cba9bf16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../download/nampdn-tiny-webtext\", exist_ok=True)\n",
    "\n",
    "def save_split(split_data, split_name, lines_per_file=100000):\n",
    "    file_idx = 1\n",
    "    line_count = 0\n",
    "    f = None\n",
    "\n",
    "    for row in split_data:\n",
    "        if line_count % lines_per_file == 0:\n",
    "            if f:\n",
    "                f.close()\n",
    "            filename = f\"../download/nampdn-tiny-webtext/{split_name}{file_idx:03d}.jsonl\"\n",
    "            f = open(filename, \"w\")\n",
    "            file_idx += 1\n",
    "\n",
    "        json.dump({\"type\": \"text\", \"content\": row[\"bot\"]}, f)\n",
    "        f.write(\"\\n\")\n",
    "        line_count += 1\n",
    "\n",
    "    if f:\n",
    "        f.close()\n",
    "\n",
    "save_split(ds[\"train\"], \"train\")\n",
    "save_split(ds[\"validation\"], \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae66fb4ebb602f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b0d8c57e0b285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
